{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Teams DataFrame\n",
    "\n",
    "Build a comprehensive teams dataset from the 2024 schedule data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the complete 2024 schedule\n",
    "schedule_df = pd.read_csv('nfl_2024_schedule.csv')\n",
    "print(f\"Loaded schedule: {len(schedule_df)} games\")\n",
    "schedule_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique team names from both home and away teams\n",
    "all_teams = set(schedule_df['home_team'].unique()) | set(schedule_df['away_team'].unique())\n",
    "\n",
    "# Create teams DataFrame\n",
    "teams_df = pd.DataFrame({\n",
    "    'team_name': sorted(list(all_teams))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build opponent lists for each team\n",
    "def get_team_opponents(team_name, schedule_df):\n",
    "    \"\"\"Get all opponents for a team in 2024\"\"\"\n",
    "    \n",
    "    # Games where team is home\n",
    "    home_games = schedule_df[schedule_df['home_team'] == team_name]\n",
    "    home_opponents = home_games['away_team'].tolist()\n",
    "    \n",
    "    # Games where team is away  \n",
    "    away_games = schedule_df[schedule_df['away_team'] == team_name]\n",
    "    away_opponents = away_games['home_team'].tolist()\n",
    "    \n",
    "    # Combine all opponents\n",
    "    all_opponents = home_opponents + away_opponents\n",
    "    \n",
    "    return all_opponents\n",
    "\n",
    "# Add opponents list to each team\n",
    "teams_df['opponents_2024'] = teams_df['team_name'].apply(\n",
    "    lambda team: get_team_opponents(team, schedule_df)\n",
    ")\n",
    "\n",
    "\n",
    "teams_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape NFL team data from Wikipedia table - handle complex merged cell structure\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def scrape_nfl_teams_wikipedia():\n",
    "    \"\"\"Scrape NFL team info from Wikipedia table - handles merged cells properly\"\"\"\n",
    "    \n",
    "    url = \"https://en.wikipedia.org/wiki/National_Football_League\"\n",
    "    \n",
    "    print(f\"Scraping {url}...\")\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find the specific NFL teams table - it's the one with Conference, Division, Team columns\n",
    "        tables = soup.find_all('table', {'class': 'wikitable'})\n",
    "        \n",
    "        for i, table in enumerate(tables):\n",
    "            # Look for the table that contains NFL team data\n",
    "            # Check if table has the right structure by looking for AFC/NFC\n",
    "            table_text = table.get_text()\n",
    "            if 'Arizona Cardinals' in table_text and 'Conference' in table_text:\n",
    "                print(f\"✓ Found NFL teams table (table {i})\")\n",
    "                \n",
    "                teams_data = []\n",
    "                current_conference = None\n",
    "                current_division = None\n",
    "                \n",
    "                # Get all rows\n",
    "                rows = table.find_all('tr')\n",
    "                \n",
    "                for row_idx, row in enumerate(rows):\n",
    "                    cells = row.find_all(['td', 'th'])\n",
    "                    \n",
    "                    if len(cells) == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    # Extract text from each cell and clean it\n",
    "                    cell_texts = []\n",
    "                    for cell in cells:\n",
    "                        text = cell.get_text().strip()\n",
    "                        # Remove footnote references [1], [2], etc.\n",
    "                        text = re.sub(r'\\\\[\\\\d+\\\\]', '', text)\n",
    "                        # Remove asterisks and daggers\n",
    "                        text = text.replace('*', '').replace('†', '').strip()\n",
    "                        cell_texts.append(text)\n",
    "                    \n",
    "                    # Skip header row\n",
    "                    if 'Conference' in cell_texts or 'Division' in cell_texts:\n",
    "                        continue\n",
    "                    \n",
    "                    # Handle different row types based on cell count and content\n",
    "                    if len(cell_texts) >= 8:\n",
    "                        # This could be a full row with conference, division, team info\n",
    "                        if cell_texts[0] in ['AFC', 'NFC']:\n",
    "                            # New conference row\n",
    "                            current_conference = cell_texts[0]\n",
    "                            current_division = cell_texts[1]\n",
    "                            \n",
    "                            # Extract team data from this row\n",
    "                            team = cell_texts[2]\n",
    "                            city = cell_texts[3]\n",
    "                            stadium = cell_texts[4]\n",
    "                            capacity = cell_texts[5]\n",
    "                            first_season = cell_texts[6]\n",
    "                            head_coach = cell_texts[7]\n",
    "                            \n",
    "                            if team and team not in ['', 'Team']:  # Valid team name\n",
    "                                teams_data.append({\n",
    "                                    'team': team,\n",
    "                                    'conference': current_conference,\n",
    "                                    'division': current_division,\n",
    "                                    'city': city,\n",
    "                                    'stadium': stadium,\n",
    "                                    'capacity': capacity,\n",
    "                                    'first_season': first_season,\n",
    "                                    'head_coach': head_coach\n",
    "                                })\n",
    "                        \n",
    "                        elif current_conference and cell_texts[0] == '':\n",
    "                            # Continuation row - just division change\n",
    "                            if cell_texts[1] in ['East', 'West', 'North', 'South']:\n",
    "                                current_division = cell_texts[1]\n",
    "                                \n",
    "                                # Extract team data\n",
    "                                team = cell_texts[2]\n",
    "                                city = cell_texts[3]\n",
    "                                stadium = cell_texts[4]\n",
    "                                capacity = cell_texts[5]\n",
    "                                first_season = cell_texts[6]\n",
    "                                head_coach = cell_texts[7]\n",
    "                                \n",
    "                                if team and team not in ['', 'Team']:\n",
    "                                    teams_data.append({\n",
    "                                        'team': team,\n",
    "                                        'conference': current_conference,\n",
    "                                        'division': current_division,\n",
    "                                        'city': city,\n",
    "                                        'stadium': stadium,\n",
    "                                        'capacity': capacity,\n",
    "                                        'first_season': first_season,\n",
    "                                        'head_coach': head_coach\n",
    "                                    })\n",
    "                    \n",
    "                    # Handle rows where team data might be in different positions\n",
    "                    elif len(cell_texts) >= 6 and current_conference:\n",
    "                        # Look for team names in the cells\n",
    "                        for idx, cell_text in enumerate(cell_texts):\n",
    "                            # Check if this looks like a team name (contains common NFL team words)\n",
    "                            team_indicators = ['Bills', 'Patriots', 'Jets', 'Dolphins', 'Ravens', 'Bengals', \n",
    "                                             'Browns', 'Steelers', 'Texans', 'Colts', 'Jaguars', 'Titans',\n",
    "                                             'Broncos', 'Chiefs', 'Raiders', 'Chargers', 'Cowboys', 'Giants',\n",
    "                                             'Eagles', 'Commanders', 'Bears', 'Lions', 'Packers', 'Vikings',\n",
    "                                             'Falcons', 'Panthers', 'Saints', 'Buccaneers', 'Cardinals', \n",
    "                                             'Rams', '49ers', 'Seahawks']\n",
    "                            \n",
    "                            if any(indicator in cell_text for indicator in team_indicators):\n",
    "                                # Found a team - try to extract data\n",
    "                                team = cell_text\n",
    "                                city = cell_texts[idx + 1] if idx + 1 < len(cell_texts) else ''\n",
    "                                stadium = cell_texts[idx + 2] if idx + 2 < len(cell_texts) else ''\n",
    "                                capacity = cell_texts[idx + 3] if idx + 3 < len(cell_texts) else ''\n",
    "                                first_season = cell_texts[idx + 4] if idx + 4 < len(cell_texts) else ''\n",
    "                                head_coach = cell_texts[idx + 5] if idx + 5 < len(cell_texts) else ''\n",
    "                                \n",
    "                                teams_data.append({\n",
    "                                    'team': team,\n",
    "                                    'conference': current_conference,\n",
    "                                    'division': current_division,\n",
    "                                    'city': city,\n",
    "                                    'stadium': stadium,\n",
    "                                    'capacity': capacity,\n",
    "                                    'first_season': first_season,\n",
    "                                    'head_coach': head_coach\n",
    "                                })\n",
    "                                break\n",
    "                \n",
    "                if teams_data:\n",
    "                    df = pd.DataFrame(teams_data)\n",
    "                    # Remove duplicates if any\n",
    "                    df = df.drop_duplicates(subset=['team'])\n",
    "                    print(f\"✓ Scraped {len(df)} teams from Wikipedia\")\n",
    "                    return df\n",
    "        \n",
    "        print(\"❌ Could not find NFL teams table\")\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        print(f\"❌ Failed to fetch Wikipedia: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Try scraping again with improved parser\n",
    "scraped_teams = scrape_nfl_teams_wikipedia()\n",
    "\n",
    "if scraped_teams is not None:\n",
    "    print(\"\\\\n✓ Successfully scraped NFL teams:\")\n",
    "    print(scraped_teams[['team', 'conference', 'division', 'stadium', 'head_coach']].head(10))\n",
    "    print(f\"\\\\nTotal teams: {len(scraped_teams)}\")\n",
    "    \n",
    "    # Check if we got all 32 teams\n",
    "    if len(scraped_teams) == 32:\n",
    "        print(\"✓ Got all 32 NFL teams!\")\n",
    "    else:\n",
    "        print(f\"⚠️  Only got {len(scraped_teams)} teams, expected 32\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Wikipedia scraping failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse city and state from the scraped Wikipedia data\n",
    "def parse_city_state(city_string):\n",
    "    \"\"\"Parse city and state from Wikipedia city field like 'Baltimore, Maryland'\"\"\"\n",
    "    if not city_string or city_string.strip() == '':\n",
    "        return '', ''\n",
    "    \n",
    "    city_string = city_string.strip()\n",
    "    \n",
    "    if ',' in city_string:\n",
    "        parts = [p.strip() for p in city_string.split(',')]\n",
    "        if len(parts) >= 2:\n",
    "            city = parts[0]\n",
    "            state = parts[1]\n",
    "            return city, state\n",
    "    \n",
    "    # If no comma, assume it's just city\n",
    "    return city_string, ''\n",
    "\n",
    "# Add city and state columns to the scraped data\n",
    "if scraped_teams is not None:\n",
    "    scraped_teams[['stadium_city', 'stadium_state']] = scraped_teams['city'].apply(\n",
    "        lambda x: pd.Series(parse_city_state(x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_teams.sort_values(by='team', inplace=True)\n",
    "scraped_teams.reset_index(drop=True, inplace=True)\n",
    "scraped_teams.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add opponents_2024 column to scraped_teams by merging with teams_df\n",
    "teams = scraped_teams.merge(\n",
    "    teams_df[['team_name', 'opponents_2024']], \n",
    "    left_on='team', \n",
    "    right_on='team_name', \n",
    "    how='left'\n",
    ").drop('team_name', axis=1)\n",
    "\n",
    "print(f\"Successfully merged opponents_2024 column\")\n",
    "print(f\"Scraped teams shape: {teams.shape}\")\n",
    "print(f\"Teams with opponents data: {teams['opponents_2024'].notna().sum()}/32\")\n",
    "\n",
    "teams.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
